import requests
import json

# URL API cho pháº§n há»™i thoáº¡i
url = "http://192.168.56.1:1234/v1/chat/completions"

# Kiá»ƒm tra káº¿t ná»‘i mÃ´ hÃ¬nh
def check_model():
    model_url = "http://192.168.56.1:1234/v1/models"
    response = requests.get(model_url)
    if response.status_code == 200:
        models = response.json()
        if len(models) > 0:
            print("âœ… MÃ´ hÃ¬nh kháº£ dá»¥ng:", models)
        else:
            print("âš ï¸ KhÃ´ng cÃ³ mÃ´ hÃ¬nh nÃ o Ä‘Æ°á»£c khá»Ÿi cháº¡y.")
    else:
        print(f"âŒ Lá»—i káº¿t ná»‘i: {response.status_code}")

# Gá»i hÃ m kiá»ƒm tra mÃ´ hÃ¬nh
check_model()

# Báº¯t Ä‘áº§u há»™i thoáº¡i
print("\nğŸ’¬ Báº¯t Ä‘áº§u trÃ² chuyá»‡n vá»›i LM Studio. GÃµ 'exit' Ä‘á»ƒ thoÃ¡t.")
messages = []

while True:
    user_input = input("ğŸ‘¤ Báº¡n: ")
    if user_input.lower() in ["exit", "thoÃ¡t"]:
        print("ğŸ‘‹ Káº¿t thÃºc trÃ² chuyá»‡n.")
        break

    # ThÃªm cÃ¢u há»i cá»§a ngÆ°á»i dÃ¹ng vÃ o danh sÃ¡ch há»™i thoáº¡i
    messages.append({"role": "user", "content": user_input})

    # Payload gá»­i lÃªn API
    payload = {
        "model": "llama2-7b-chat",  # Thay báº±ng mÃ´ hÃ¬nh báº¡n Ä‘Ã£ chá»n
        "messages": messages,
        "max_tokens": 100,
        "temperature": 0.7
    }

    headers = {
        "Content-Type": "application/json"
    }

    try:
        # Gá»­i yÃªu cáº§u POST Ä‘áº¿n LM Studio
        response = requests.post(url, headers=headers, data=json.dumps(payload))
        if response.status_code == 200:
            reply = response.json()["choices"][0]["message"]["content"]
            print(f"ğŸ¤– LM Studio: {reply}")
            # ThÃªm cÃ¢u tráº£ lá»i cá»§a mÃ´ hÃ¬nh vÃ o há»™i thoáº¡i Ä‘á»ƒ giá»¯ ngá»¯ cáº£nh
            messages.append({"role": "assistant", "content": reply})
        else:
            print(f"âŒ Lá»—i káº¿t ná»‘i: {response.status_code}")
    except Exception as e:
        print(f"âš ï¸ Lá»—i khi gá»­i yÃªu cáº§u: {e}")
